#### Before the Beginning
Many moons ago, when the idea that would eventually become the Jenjin was first taking shape, I assumed that handling movement of players across clients would be simple.  What a fool I was.  Back in those days, I knew next to nothing about network programming, serialization, or multithreading.  The very first version of the Jenjin (then called something asinine I can't even remember) hooked directly into the Java Swing thread, because I didn't know any better.  I wrote a neat little tile-based game, then said to myself "Ok, now I'll just make it multiplayer!"  My idea of a persistent game state... Well, I don't want to get into it, but let's just say it involved a java.util.Properties class.  It wasn't pretty, and it broke if you sneezed during the wrong processor cycle.  Or the right processor cycle, for that matter.  It was a clunky piece of garbage, if I'm being honest.

None of this is really relevant to the story I'm about to tell you, but I think you might have some more sympathy for me if you realize exactly what manner of idiot I was when I, many years later, actually started serious drafting of the Jenjin.  I was a colossal one.

- - - 

#### The Early Days
A few years ago, sometime in early 2011, I started working on a game.  Or rather, I *re*-started working on the same game I'd been childishly persuing since I was in the eighth grade.  Only this time, things were drastically different; my entire programming portfolio had been destroyed in a fire, I was delivering pizza full time, and working on my Computer Science degree.  I was bored with my classes, and I had a lot of free time in the slow day shifts at work, so I started keeping a journal and drafting up my ideas for an MMORPG.  In my classes, I started writing some basic prototype code for the server and client, teaching myself network programming, serialization, and multithreading as I went.  I can't even remember how many rewrites the entire codebase went through before I settled on the basic idea that's still being used now (although in a much more refined state).  I spent days buried in programming books, lurking on StackOverflow, and pestering my CompSci professors.  And when everything was said and done, I had a client and a server and a flexible system for reliably sending messages in a non-blocking fasion from one two the other, without interrupting the flow of either program.

I felt like a badass.

So, since I had this wonderful new client and server, I wanted to use them to make a game.  Not a framework, or an API, mind you, but a game, with like, monsters, and weapons and stuff, and it's gonna be *so cool*!  Now, after the dozens of rewrites I'd forced myself to endure, I had learned to plan ahead, and I decided to draft up a list of basic requirements for a game.  The first thing was the ability to log in.  Then being able to see other players, and for other players to see you.  Then to move around, and for you to be in the same place on everyone's client.  Whew.  Woooo boy.  Ok, that's as far as I remember making that list, because, *holy shit* movement was really hard.  Is really hard.  Years later, I'm still pretty sure there's a better way of doing it than I am currently.  I just came up with a new one a few weeks ago, actually, and I'm working on implementing it.

#### Movement I
The first movement system I came up with worked.  In fact, if there were no such things as bandwidth speeds or data caps, I'm pretty sure it's the fastest, most accurate movement system that can possibly exist.  The server was broadcasting every position of every player to every other player, once per update, dozens of updates per second.  That is a whole lot of bandwidth.  I don't remember the exact numbers I came up with, but assuming every player's position is stored in a pair of floats (8 bytes each) and that's the *only* data that needed the be broadcast for each player, 50 players standing in sight of each other, that's roughly 16Mbps of data flying around, *even if nothing is happening*.

Being an idiot, I started optimizing this nonsense.  I actually had some respectable numbers, I think, as long as there weren't too many players in the same place and as long as they didn't move very much.  But I wanted this project to scale.  I didn't even know what scalability was back then, but I knew that I wanted it.

Part of my efforts to make this system more feasable was by reducing the frequency of broadcasts, limiting them so that each player only got two or three broadcasts per second instead of the 50 I had been shooting for.  Less bandwidth, more lag and judder.  I tried a few other things, but nothing really helped.

#### Movement II - The Great Divide
I had to drastically rethink how I was storing and sending player positions.  When did a given client (Alice) need to know a given player's (Bob's) position?  When Alice first "sees" Bob, she needs to know where he is.  She also needs to know when she can't see him any more.  What about in between?  She has to know when he starts and stops moving, and when he changes direction.  If she knows that, she can figure out "sort of" where he should be at a given time.  Then, when the server says "Bob turned left after 2 seconds" Alice can figure out where Bob was 2 seconds ago, and fix his position based on that.  Simple, right?

This system worked *much* more effeciently.  I went in the total opposite direction from my previous thoughts, and started treating bandwidth like it was gold, and CPU cycles like they were dirt.  Calculating positions when new player states were received took a lot of CPU power compared to just putting them where the server said to.  But that wasn't really a big problem; after all, these states weren't being handled for every player every update, and didn't take *that* much CPU time.  

No, the real problem here was accuracy.  You see, I was placing the players based on *when* the message was sent, and because the amount of time between updates is slightly different from one to the next, and there are even more descrepencies between the client and server update cycles.  Players were ending up skewed to the left on client, and to the left on another.  A third might have them spot on.  And because of the correction occurring when a player changed state, there was always a little "jump" when they changed direction, or stopped, or started.  Gross.

However, I kept telling myself that this would be fine; as long as the visual representation of the players (be it a sprite, or a 3D model, or whatever) was scaled properly, the jumps wouldn't even be noticable.  And as long as the players were getting corrected when the state changed, they could be off by a little bit compared to one another, no big deal.  

Finally, though, I started seeing how large the descrepencies could be after two players stood near each other for long periods of time.  I'd start moving, and the test client would launch me halfway across the screen to where it thought I should be, then rocket me back when I stopped moving again.  Unacceptable.

#### Movement III - The Revenge
In researching my positioning woes, I realized that my timing-based system would never be as accurate as the position-based system I had originally implemented, and the code for it is just gross.  I was hashing out the issues with one of my cats (a technique I often use in place of "Rubber Duck Debugging" because honestly those damned rubber ducks always seem so judgemental) when the solution hit me.  It all seemed so obvious!  If I used a combination of the two, I could achieve massive gains in accuracy and lose only a small amount of bandwidth.

So, along with the time and state of change (hereafter referred to as the **State**), the message to the client now includes the player's *position* of change.  This means that the client does not have to calculate the player's position of change based on the time passed since the change, which decreases both the innaccuracy of the player's **State** position (which is affected both by the latency between the client and server, and the time of the update on the client) as well as the CPU time required to calculate this position.  This does, however, add 16 bytes to the message, which eats a small amount of bandwidth.

This change increases the accuracy of player positioning, and stops the accumulation of position offset incurred by the discrepencies in timing.  This stops players who are near each other for long periods from "jumping" when their states change, and stops the characteristic "jump" visible to clients when their player stops moving.
